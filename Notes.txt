1. To create a project use:  
scrapy startproject <name>

2. Activate virtual environemnt
pip install virtualenv
python3 -m venv venv
source venv/bin/activate

3. Install scrapy

4. Create a spider
Command: navigate to spiders folder 
scrapy genspider <name> <url>

5. Command
Change in setting.cfg shell = ipython
pip install ipython
scrapy shell

6. Example :
In [9]: book.css('h3 a::text').get()
Out[9]: 'A Light in the ...'

7. What does the Yield Keyword do?
Ans: Yield keyword is used to create a generator function. A type of function that is memory efficient and can be used like an iterator object.

8. Xpaths:
response.xpath("//ul[@class='breadcrumb']/li[@class='active']/preceding-sibling::li[1]/a/text()").get()

response.xpath("//div[@id='product_description']/following-sibling::p/text()").get()

9. response.css('p.star-rating').attrib['class']

10. Save :
csv: scrapy crawl bookspider -O bookdata.csv
json: scrapy crawl bookspider -O bookdata.json

11. Pipelines are used to clean the data

12. sudo mysql -u root

13. Most life saving article :
create database books;
https://computingforgeeks.com/how-to-install-mariadb-on-kali-linux/

14. sudo mysql -u root -p

15. https://useragentstring.com/

16. Fake Headers API
https://scrapeops.io/

17. Middle Attach in download middlewares for rotating headers while scrapping

18. For installing rotating proxy module (Helpful for scrapy 
in setting 

Also refer docs for complete setup of it in the middlewares

ROTATING_PROXY_LIST = [
   'proxy1.com:8000',
   'proxy2.com:8031',
   'proxy3.com:8032',
]
) :
pip install scrapy-rotating-proxies

19.  pip install scrapeops-scrapy-proxy-sdk
